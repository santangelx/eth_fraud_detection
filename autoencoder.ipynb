{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efafa460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1f49a",
   "metadata": {},
   "source": [
    "# Data import and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d5bc72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"transaction_dataset.csv\")\n",
    "\n",
    "#Rename columns for easier access\n",
    "df.columns = df.columns.str.strip().str.replace(' ','_').str.lower()\n",
    "\n",
    "#Remove weird stuff \n",
    "df.drop(columns=['unnamed:_0'], inplace=True)\n",
    "\n",
    "#Remove duplicate accounts\n",
    "df.drop_duplicates(subset=['address'], inplace=True)\n",
    "\n",
    "#Remove accounts \n",
    "df.drop(columns=['address'], inplace=True)\n",
    "\n",
    "#Remove index\n",
    "df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "#Remove token names \n",
    "df.drop(columns=['erc20_most_sent_token_type','erc20_most_rec_token_type'], inplace = True)\n",
    "\n",
    "#Remove var=0 columns\n",
    "df.drop(df.var(numeric_only=True)[df.var(numeric_only=True) == 0].index, axis = 1, inplace = True)\n",
    "\n",
    "#Remove small distribution columns\n",
    "small_distr_col = []\n",
    "for col in df.columns[3:] :\n",
    "    if len(df[col].value_counts()) < 10:\n",
    "        small_distr_col.append(col)\n",
    "df.drop(columns=small_distr_col,inplace = True)\n",
    "\n",
    "\n",
    "#Replace nan values by median \n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "# Remove negative values \n",
    "df[df<0] = None \n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df_n = df.copy()\n",
    "\n",
    "#Normalization \n",
    "for col in df_n.columns:\n",
    "    df_n[col] = (df_n[col]-df_n[col].mean())/df_n[col].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c38eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accounts(torch.utils.data.Dataset):\n",
    "    def __init__(self,df):\n",
    "\n",
    "        x=df.iloc[:,1:].values\n",
    "        y=df.iloc[:,0].values\n",
    "\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "        self.y_train=torch.tensor(y,dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx],self.y_train[idx]\n",
    "\n",
    "full_data = Accounts(df_n)\n",
    "train_size = int(0.8 * len(full_data))\n",
    "test_size = len(full_data) - train_size\n",
    "train_data, test_data = torch.utils.data.random_split(full_data, \n",
    "                        [train_size, test_size],torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51c4db",
   "metadata": {},
   "source": [
    "# Pytorch Autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06459e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 33          # size of each input\n",
    "HIDDEN_DIM = 30         # hidden dimension\n",
    "LATENT_DIM = 10         # latent vector dimension\n",
    "N_CLASSES = 1           # number of classes in the data\n",
    "lr = 0.001              # learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d35de422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, n_classes):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: A integer indicating the size of input (in case of MNIST 28 * 28).\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            latent_dim: A integer indicating the latent size.\n",
    "            n_classes: A integer indicating the number of classes. (dimension of one-hot representation of labels)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(input_dim + n_classes, input_dim)\n",
    "        self.linear1 = nn.Linear(input_dim , hidden_dim)\n",
    "        self.latent = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim + n_classes]\n",
    "\n",
    "        x = torch.tanh(self.linear(x))\n",
    "        # hidden is of shape [batch_size, hidden_dim]\n",
    "        x = torch.tanh(self.linear1(x))\n",
    "        # latent parameters\n",
    "        encode = self.latent(x)\n",
    "\n",
    "        return encode\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "\n",
    "    '''\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim, n_classes):\n",
    "        '''\n",
    "        Args:\n",
    "            latent_dim: A integer indicating the latent size.\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            output_dim: A integer indicating the size of output (in case of MNIST 28 * 28).\n",
    "            n_classes: A integer indicating the number of classes. (dimension of one-hot representation of labels)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_to_hidden = nn.Linear(latent_dim + n_classes, hidden_dim)\n",
    "        self.hidden_to_hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.hidden_to_out = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, latent_dim + num_classes]\n",
    "        x = torch.tanh(self.latent_to_hidden(x))\n",
    "        # x is of shape [batch_size, hidden_dim]\n",
    "        x = torch.tanh(self.hidden_to_hidden(x))\n",
    "        generated_x = self.hidden_to_out(x)\n",
    "        # x is of shape [batch_size, output_dim]\n",
    "\n",
    "        return generated_x\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, n_classes):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: A integer indicating the size of input (in case of MNIST 28 * 28).\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            latent_dim: A integer indicating the latent size.\n",
    "            n_classes: A integer indicating the number of classes. (dimension of one-hot representation of labels)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim, n_classes)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim, n_classes)\n",
    "\n",
    "    def forward(self, x, C1):\n",
    "\n",
    "        x = torch.cat((x, C1), dim=1)\n",
    "\n",
    "        # encode\n",
    "        encoded = self.encoder(x)\n",
    "\n",
    "        z = torch.cat((encoded, C1), dim=1)\n",
    "\n",
    "\n",
    "        # decode\n",
    "        generated_x = self.decoder(z)\n",
    "\n",
    "        return generated_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123048ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CVAE(INPUT_DIM, HIDDEN_DIM, LATENT_DIM, N_CLASSES)\n",
    "\n",
    "#optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1afc409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x, reconstructed_x):\n",
    "    # reconstruction loss\n",
    "    mse = nn.MSELoss()\n",
    "    RCL = mse(reconstructed_x, x)\n",
    "\n",
    "    return RCL \n",
    "def train():\n",
    "    # set the train mode\n",
    "    model.train()\n",
    "\n",
    "    # loss of the epoch\n",
    "    train_loss = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(train_data):\n",
    "        # reshape the data into [batch_size, 33]\n",
    "        x = x.view(-1, INPUT_DIM)\n",
    "        x = x.to(device)\n",
    "\n",
    "        # reshape the label\n",
    "        y = y.view(-1, 1)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # update the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        reconstructed_x= model(x, y)\n",
    "\n",
    "        # loss\n",
    "        loss = calculate_loss(x, reconstructed_x)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss\n",
    "def test():\n",
    "    # set the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # test loss for the data\n",
    "    test_loss = 0\n",
    "\n",
    "    # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(test_data):\n",
    "            # reshape the data\n",
    "            x = x.view(-1, INPUT_DIM)\n",
    "            x = x.to(device)\n",
    "\n",
    "            # reshape the label\n",
    "            y = y.view(-1, 1)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            reconstructed_x= model(x, y)\n",
    "\n",
    "            # loss\n",
    "            loss = calculate_loss(x, reconstructed_x)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221c2c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.8446, Test Loss: 0.6129\n",
      "Epoch 1, Train Loss: 0.7701, Test Loss: 0.5640\n",
      "Epoch 2, Train Loss: 0.7364, Test Loss: 0.5209\n",
      "Epoch 3, Train Loss: 0.7099, Test Loss: 0.4886\n",
      "Epoch 4, Train Loss: 0.6833, Test Loss: 0.4867\n",
      "Epoch 5, Train Loss: 0.6680, Test Loss: 0.4486\n",
      "Epoch 6, Train Loss: 0.6461, Test Loss: 0.4379\n",
      "Epoch 7, Train Loss: 0.6339, Test Loss: 0.4323\n",
      "Epoch 8, Train Loss: 0.6263, Test Loss: 0.4585\n",
      "Epoch 9, Train Loss: 0.6111, Test Loss: 0.4233\n",
      "Epoch 10, Train Loss: 0.6145, Test Loss: 0.4230\n",
      "Epoch 11, Train Loss: 0.5967, Test Loss: 0.4037\n",
      "Epoch 12, Train Loss: 0.5904, Test Loss: 0.3976\n",
      "Epoch 13, Train Loss: 0.5779, Test Loss: 0.3964\n",
      "Epoch 14, Train Loss: 0.5703, Test Loss: 0.3851\n",
      "Epoch 15, Train Loss: 0.5602, Test Loss: 0.3847\n",
      "Epoch 16, Train Loss: 0.5538, Test Loss: 0.3859\n",
      "Epoch 17, Train Loss: 0.5444, Test Loss: 0.3797\n",
      "Epoch 18, Train Loss: 0.5396, Test Loss: 0.3806\n",
      "Epoch 19, Train Loss: 0.5422, Test Loss: 0.3631\n",
      "Epoch 20, Train Loss: 0.5308, Test Loss: 0.3557\n",
      "Epoch 21, Train Loss: 0.5269, Test Loss: 0.3742\n",
      "Epoch 22, Train Loss: 0.5161, Test Loss: 0.3654\n",
      "Epoch 23, Train Loss: 0.5112, Test Loss: 0.3478\n",
      "Epoch 24, Train Loss: 0.5081, Test Loss: 0.3475\n",
      "Epoch 25, Train Loss: 0.5198, Test Loss: 0.3421\n",
      "Epoch 26, Train Loss: 0.5059, Test Loss: 0.3610\n",
      "Epoch 27, Train Loss: 0.5103, Test Loss: 0.3382\n",
      "Epoch 28, Train Loss: 0.5059, Test Loss: 0.3534\n",
      "Epoch 29, Train Loss: 0.5059, Test Loss: 0.3503\n",
      "Epoch 30, Train Loss: 0.4930, Test Loss: 0.3774\n"
     ]
    }
   ],
   "source": [
    "patience_counter = 0\n",
    "for e in range(100):\n",
    "\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_loss /= len(train_data)\n",
    "    test_loss /= len(test_data)\n",
    "\n",
    "    print(f'Epoch {e}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "    if e==0 :\n",
    "        best_test_loss = test_loss +1\n",
    "\n",
    "    if best_test_loss > test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 1\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7208d635",
   "metadata": {},
   "source": [
    "# Testing the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7a8a190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09454811 -0.16814876  3.2567217   7.2087145   3.5418043   0.5459452\n",
      "  0.13669589  1.0874665   0.9293145   0.06411216  0.94818056 -0.2539101\n",
      " -0.07918754 -0.40806633  6.3791194  -0.11438954 -0.12140414  0.1091944\n",
      "  0.12534976  0.51199734  0.28003109 -0.17113006  0.30476052  0.13019621\n",
      "  0.75335777  0.9649465   0.45672736  0.28642964  0.2719013   0.2505895\n",
      "  0.27604955 -0.03742063  0.8336555 ]\n",
      "[[-2.1663022e-01 -3.1607282e-01  5.1154518e+00  5.3325658e+00\n",
      "   3.5575812e+00 -2.4795942e-02 -4.7033362e-02 -6.6713274e-02\n",
      "  -1.4117777e-01 -3.4495737e-02 -1.8146957e-01 -3.1942267e-02\n",
      "  -3.6905438e-02 -1.8245962e-01  5.3095746e+00  4.0037413e-03\n",
      "  -8.0520296e-03 -2.3171857e-02 -4.1231211e-02 -4.5108795e-02\n",
      "  -1.1236985e-02 -1.8277075e-02 -4.0498100e-02  6.5580852e-02\n",
      "   5.0790775e-01 -2.5317864e-02 -4.0298436e-02 -2.0982658e-02\n",
      "  -1.1128101e-02 -1.0868262e-02 -1.0761774e-02 -1.2688458e-01\n",
      "   5.3006876e-01]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, (x, y) in enumerate(test_data):\n",
    "    x = x.view(-1, INPUT_DIM)\n",
    "    x = x.to(device)\n",
    "\n",
    "    # reshape the label\n",
    "    y = y.view(-1, 1)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # forward pass\n",
    "    x_r= model(x, y)\n",
    "    x_r = x_r.detach().numpy()[0]\n",
    "    print(x_r)\n",
    "    print(x.numpy())\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec993d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
