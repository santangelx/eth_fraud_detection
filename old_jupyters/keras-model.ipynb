{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethereum Fraud Detection\n",
    "\n",
    "Building a DNN using Keras and a preprocessing pipeline. Note that we got worse accuracy using this than a XGboost model [here](https://www.kaggle.com/stuartday274/basic-xgb-model) but was a fun learning experience. If anyone has any pointers to improve the accuracy I'd love to hear them :) \n",
    "\n",
    "Here is a description of the rows of the dataset:\n",
    "- Index: the index number of a row\n",
    "- Address: the address of the ethereum account\n",
    "- FLAG: whether the transaction is fraud or not\n",
    "- Avg min between sent tnx: Average time between sent transactions for account in minutes\n",
    "- Avgminbetweenreceivedtnx: Average time between received transactions for account in minutes\n",
    "- TimeDiffbetweenfirstand_last(Mins): Time difference between the first and last transaction\n",
    "- Sent_tnx: Total number of sent normal transactions\n",
    "- Received_tnx: Total number of received normal transactions\n",
    "- NumberofCreated_Contracts: Total Number of created contract transactions\n",
    "- UniqueReceivedFrom_Addresses: Total Unique addresses from which account received transactions\n",
    "- UniqueSentTo_Addresses20: Total Unique addresses from which account sent transactions\n",
    "- MinValueReceived: Minimum value in Ether ever received\n",
    "- MaxValueReceived: Maximum value in Ether ever received\n",
    "- AvgValueReceived5Average value in Ether ever received\n",
    "- MinValSent: Minimum value of Ether ever sent\n",
    "- MaxValSent: Maximum value of Ether ever sent\n",
    "- AvgValSent: Average value of Ether ever sent\n",
    "- MinValueSentToContract: Minimum value of Ether sent to a contract\n",
    "- MaxValueSentToContract: Maximum value of Ether sent to a contract\n",
    "- AvgValueSentToContract: Average value of Ether sent to contracts\n",
    "- TotalTransactions(IncludingTnxtoCreate_Contract): Total number of transactions\n",
    "- TotalEtherSent:Total Ether sent for account address\n",
    "- TotalEtherReceived: Total Ether received for account address\n",
    "- TotalEtherSent_Contracts: Total Ether sent to Contract addresses\n",
    "- TotalEtherBalance: Total Ether Balance following enacted transactions\n",
    "- TotalERC20Tnxs: Total number of ERC20 token transfer transactions\n",
    "- ERC20TotalEther_Received: Total ERC20 token received transactions in Ether\n",
    "- ERC20TotalEther_Sent: Total ERC20token sent transactions in Ether\n",
    "- ERC20TotalEtherSentContract: Total ERC20 token transfer to other contracts in Ether\n",
    "- ERC20UniqSent_Addr: Number of ERC20 token transactions sent to Unique account addresses\n",
    "- ERC20UniqRec_Addr: Number of ERC20 token transactions received from Unique addresses\n",
    "- ERC20UniqRecContractAddr: Number of ERC20token transactions received from Unique contract addresses\n",
    "- ERC20AvgTimeBetweenSent_Tnx: Average time between ERC20 token sent transactions in minutes\n",
    "- ERC20AvgTimeBetweenRec_Tnx: Average time between ERC20 token received transactions in minutes\n",
    "- ERC20AvgTimeBetweenContract_Tnx: Average time ERC20 token between sent token transactions\n",
    "- ERC20MinVal_Rec: Minimum value in Ether received from ERC20 token transactions for account\n",
    "- ERC20MaxVal_Rec: Maximum value in Ether received from ERC20 token transactions for account\n",
    "- ERC20AvgVal_Rec: Average value in Ether received from ERC20 token transactions for account\n",
    "- ERC20MinVal_Sent: Minimum value in Ether sent from ERC20 token transactions for account\n",
    "- ERC20MaxVal_Sent: Maximum value in Ether sent from ERC20 token transactions for account\n",
    "- ERC20AvgVal_Sent: Average value in Ether sent from ERC20 token transactions for account\n",
    "- ERC20UniqSentTokenName: Number of Unique ERC20 tokens transferred\n",
    "- ERC20UniqRecTokenName: Number of Unique ERC20 tokens received\n",
    "- ERC20MostSentTokenType: Most sent token for account via ERC20 transaction\n",
    "- ERC20MostRecTokenType: Most received token for account via ERC20 transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('transaction_dataset.csv')\n",
    "df.columns = [x.lower() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    ' erc20 most sent token type',\n",
    "    ' erc20_most_rec_token_type',\n",
    "    'address',\n",
    "    'index',\n",
    "    'unnamed: 0'\n",
    "]\n",
    "\n",
    "features = [x for x in df.columns if (x != 'flag' and x not in cols_to_drop)]\n",
    "\n",
    "unique_values = df.nunique()\n",
    "\n",
    "features = [x for x in features if x in unique_values.loc[(unique_values>1)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9841 entries, 0 to 9840\n",
      "Data columns (total 38 columns):\n",
      " #   Column                                                Non-Null Count  Dtype  \n",
      "---  ------                                                --------------  -----  \n",
      " 0   avg min between sent tnx                              9841 non-null   float64\n",
      " 1   avg min between received tnx                          9841 non-null   float64\n",
      " 2   time diff between first and last (mins)               9841 non-null   float64\n",
      " 3   sent tnx                                              9841 non-null   int64  \n",
      " 4   received tnx                                          9841 non-null   int64  \n",
      " 5   number of created contracts                           9841 non-null   int64  \n",
      " 6   unique received from addresses                        9841 non-null   int64  \n",
      " 7   unique sent to addresses                              9841 non-null   int64  \n",
      " 8   min value received                                    9841 non-null   float64\n",
      " 9   max value received                                    9841 non-null   float64\n",
      " 10  avg val received                                      9841 non-null   float64\n",
      " 11  min val sent                                          9841 non-null   float64\n",
      " 12  max val sent                                          9841 non-null   float64\n",
      " 13  avg val sent                                          9841 non-null   float64\n",
      " 14  min value sent to contract                            9841 non-null   float64\n",
      " 15  max val sent to contract                              9841 non-null   float64\n",
      " 16  avg value sent to contract                            9841 non-null   float64\n",
      " 17  total transactions (including tnx to create contract  9841 non-null   int64  \n",
      " 18  total ether sent                                      9841 non-null   float64\n",
      " 19  total ether received                                  9841 non-null   float64\n",
      " 20  total ether sent contracts                            9841 non-null   float64\n",
      " 21  total ether balance                                   9841 non-null   float64\n",
      " 22   total erc20 tnxs                                     9012 non-null   float64\n",
      " 23   erc20 total ether received                           9012 non-null   float64\n",
      " 24   erc20 total ether sent                               9012 non-null   float64\n",
      " 25   erc20 total ether sent contract                      9012 non-null   float64\n",
      " 26   erc20 uniq sent addr                                 9012 non-null   float64\n",
      " 27   erc20 uniq rec addr                                  9012 non-null   float64\n",
      " 28   erc20 uniq sent addr.1                               9012 non-null   float64\n",
      " 29   erc20 uniq rec contract addr                         9012 non-null   float64\n",
      " 30   erc20 min val rec                                    9012 non-null   float64\n",
      " 31   erc20 max val rec                                    9012 non-null   float64\n",
      " 32   erc20 avg val rec                                    9012 non-null   float64\n",
      " 33   erc20 min val sent                                   9012 non-null   float64\n",
      " 34   erc20 max val sent                                   9012 non-null   float64\n",
      " 35   erc20 avg val sent                                   9012 non-null   float64\n",
      " 36   erc20 uniq sent token name                           9012 non-null   float64\n",
      " 37   erc20 uniq rec token name                            9012 non-null   float64\n",
      "dtypes: float64(32), int64(6)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "df[features].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class BasePipeStep(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns=[]):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        return X\n",
    "    \n",
    "class SelectColumns(BasePipeStep):\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        return X[self.columns]\n",
    "    \n",
    "class FillNumericData(BasePipeStep):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.means = { col: X[col].mean() for col in self.columns}\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            X[col] = X[col].fillna(self.means[col])\n",
    "        return X\n",
    "\n",
    "\n",
    "class ScaleNumeric(BasePipeStep):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(X[self.columns])\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.columns] = self.scaler.transform(X[self.columns])\n",
    "        return X\n",
    "\n",
    "class GetValues(BasePipeStep):\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        return X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "preprocessing = Pipeline([\n",
    "    ('feature_selection', SelectColumns(features)),\n",
    "    ('fill_missing', FillNumericData(features)),\n",
    "    ('standard_scaling', ScaleNumeric(features)),\n",
    "    ('returnValues', GetValues())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\tziya\\anaconda3\\lib\\site-packages (2.7.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X = df[features]\n",
    "y = df['flag']\n",
    "y = to_categorical(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([test_prediction]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessing.fit_transform(X_train)\n",
    "X_test = preprocessing.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 38)                1482      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20)                780       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5)                 105       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,379\n",
      "Trainable params: 2,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Input(shape=(len(features),)))\n",
    "\n",
    "model.add(Dense(len(features), activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 817, in train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 439, in update_state\n        self.build(y_pred, y_true)\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 359, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 485, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 485, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 504, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 3785, in get\n        return deserialize(str(identifier))\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 3741, in deserialize\n        return deserialize_keras_object(\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 708, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: false_positive. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12716/4001834483.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 817, in train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 439, in update_state\n        self.build(y_pred, y_true)\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 359, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 485, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 485, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 504, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 3785, in get\n        return deserialize(str(identifier))\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 3741, in deserialize\n        return deserialize_keras_object(\n    File \"C:\\Users\\tziya\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 708, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: false_positive. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721\n",
      "721\n",
      "(1, 1, 3248)\n",
      "11\n",
      "3248\n",
      "Accuracy: 77.71%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "test_prediction = [np.argmax(x) for x in model.predict(X_test)]\n",
    "\n",
    "acc = metrics.accuracy_score(test_prediction, [np.argmax(y) for y in y_test])\n",
    "\n",
    "real_answers = [np.argmax(y) for y in y_test]\n",
    "\n",
    "real_answers = np.array([real_answers])\n",
    "\n",
    "test_prediction = np.array([test_prediction])\n",
    "\n",
    "print(real_answers.sum())\n",
    "print(real_answers.sum())\n",
    "\n",
    "print(np.array([test_prediction]).shape)\n",
    "print(np.array([test_prediction]).sum())\n",
    "print((np.array([test_prediction]).size))\n",
    "\n",
    "print(f'Accuracy: {acc:,.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC of Model On Test Set - 58.11%\n",
      "4.0\n",
      "717.0\n",
      "2520.0\n",
      "7.0\n",
      "tf.Tensor(0.57106745, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "score = metrics.roc_auc_score([np.argmax(y) for y in y_test], model.predict(X_test)[:,1])\n",
    "\n",
    "score1 = keras.metrics.AUC(\n",
    "    num_thresholds=200,\n",
    "    curve=\"ROC\",\n",
    "    summation_method=\"interpolation\",\n",
    "    name=None,\n",
    "    dtype=None,\n",
    "    thresholds=None,\n",
    "    multi_label=False,\n",
    "    num_labels=None,\n",
    "    label_weights=None,\n",
    "    from_logits=False,\n",
    ")\n",
    "print(f'Area under ROC of Model On Test Set - {score:,.2%}')\n",
    "\n",
    "m = keras.metrics.TruePositives()\n",
    "m.update_state(test_prediction, real_answers)\n",
    "print(m.result().numpy())\n",
    "\n",
    "m = keras.metrics.FalsePositives()\n",
    "m.update_state(test_prediction, real_answers)\n",
    "print(m.result().numpy())\n",
    "\n",
    "m = keras.metrics.TrueNegatives()\n",
    "m.update_state(test_prediction, real_answers)\n",
    "print(m.result().numpy())\n",
    "\n",
    "m = keras.metrics.FalseNegatives()\n",
    "m.update_state(test_prediction, real_answers)\n",
    "print(m.result().numpy())\n",
    "\n",
    "score1.update_state(test_prediction, real_answers)\n",
    "print(score1.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
